## 모형 검증 및 최적화(Model Validation & Optimization)

#### 모델 검증

* 모델의 Variance, Bias 등을 통해 모델의 성능을 평가함



#### 모델 최적화

- 단일 파라미터 혹은 복수 파라미터의 조합으로 모델을 실험하며 최적의 예층 성능을 갖는 파라미터를 찾아냄



### Validation_curve

- 단일 하이퍼 파라미터를 최적화하는 방법론

1)  데이터 블러오기, 파라미터 범위 설정

```python
from sklearn.datasets import load_digits
from sklearn.svm import SVC
from sklearn.model_selection import validation_curve
# x,y 데이터 불러오기
digits = load_digits()
X, y = digits.data, digits.target
# log -6승~ -1승까지 범위를 10분할로 나누어 리스트화
param_range = np.logspace(-6,-1, 10)
```

2) validation_curve 함수로 하이퍼 파라미터가 변화할 때의 validation 값을 측정함

```python
%%time
train_scores, test_scores = \
    validation_curve(SVC(), X, y,
                     param_name="gamma", param_range=param_range,
                     cv=10, scoring="accuracy", n_jobs=1)
```

3) 시각화를 통해 Training Score와 Cross-Validation Score를 비교해본다.

```python
mpl.rcParams["font.family"] = 'DejaVu Sans'
plt.semilogx(param_range, train_scores_mean, label="Training score", color="r")
plt.fill_between(param_range, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.2, color="r")
plt.semilogx(param_range, test_scores_mean,
             label="Cross-validation score", color="g")
plt.fill_between(param_range, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.2, color="g")
plt.legend(loc="best")
plt.title("Validation Curve with SVC")
plt.xlabel("$\gamma$")
plt.ylabel("Score")
plt.ylim(0.0, 1.1)
plt.show()
```



![모형최적화(20210520)](image/모형최적화(20210520).png)

4)  Validation Score의 해석



* validation curve는 파라미터를 통해 모델을 평가하는데 쓰일 뿐 튜닝을 하는데 쓰이면 안된다.

-> 만약 validation curve를 바탕으로 파라미터 튜닝을 한다면 모델의 일반화가 부족하고 편향된 값이 나와 test 했을 때 더 좋지 않다. 

-> 최적의 parameter를 구해서 모델에 쓰는게 목적이 아니면 왜 찾나?

ML model의 validation을 위해 쓴다. 

* training score와 cross-validation score 그래프가 비슷할수록 좋다.
* 만약 두 값이(t/s, c-v/s) 모두 낮으면 일반화가 많이 되었거나 모델이 단순해 underfitting되었다는 의미
* 만약 training score가 급격히 높아지지만 validation_curve가 계속 낮다면 모델이 복잡하거나 데이터가 적어 overfitting 되었다는 의미

5) Variance와 Bias의 Trade-off

![모형최적화_2(20210520)](image/모형최적화_2(20210520).png)

출처) https://modulabs-biomedical.github.io/Bias_vs_Variance

이 수식은 MSE(Mean Squared Error) 를 풀었을 때 추정값에 대한 Var+ Bias의 합이 된다는 것을 의미함

결국 분산과 편향은 서로 반비례하는 관계임을 알 수 있음

수식을 풀어보자면,

분산은 추정값과 추정값의 평균이 떨어진 정도의 제곱에 대한 평균

-> 즉 얼마나 우리가 예측한 값들이 분산되어 있는지를 보여줌

편향성은 추정값의 평균과 실제 모수와의 차이에 대한 제곱

-> 즉 예측값의 평균과 실제값의 거리를 보여주는 지표가 됨

이 두가지를 합하였을 때 추정치-모수의 제곱의 평균-> MSE가 되는 걸 알 수 있음



### Grid_Search

- 다양한 파라미터의 조합을 루프로 돌며 최적의 파라미터를 찾아내는 방법론

#### Grid_Search Input 코드

```python
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()
params = {
    'n_neighbors' : [5, 25],
    'weights': ['uniform', 'distance'],
    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']
}
grid_kn = GridSearchCV(estimator = kn,
                        param_grid = params,
                        scoring = 'accuracy', 
                        cv = 5, 
                        verbose = 1,
                        n_jobs = -1)
grid_kn.fit(X_train, y_train)

```

* param_grid : dict 형태 -> value값을 리스트로 구성하여 테스트하고 싶은 파라미터 옵션들을 모두 넣어줌
* scoring : CV 시 parameter 튜닝의 지표로 쓸 값(ex. accuracy, roc_curve) 
* cv : cross-validation의 폴드 개수
* verbose: 1로 하면 모델의 디테일 정보 표시해줌
* n_jobs :  -1  -> 가용한 모든 cpu를 사용해 다수의 모델을 동시에 돌림, n -> cpu 중 n개 사용



#### GridSearch Output 코드

```python
grid_kn.cv_results()
grid_kn.best_params()
grid_kn.best_score()
```

* cv_result: dictionary 내에 모델과 관련된 모든 값이 들어가 있음
* best_params: dictionary 형태로 딕셔너리를 최적 상태에서의 파라미터 조합을 반환함
* best_score: 최적 상태에서의 score값을 반환함



참고문헌:

1) https://datascienceschool.net/03%20machine%20learning/14.01%20%EB%AA%A8%ED%98%95%20%EC%B5%9C%EC%A0%81%ED%99%94.html

2) https://www.geeksforgeeks.org/validation-curve/

3) https://modulabs-biomedical.github.io/Bias_vs_Variance